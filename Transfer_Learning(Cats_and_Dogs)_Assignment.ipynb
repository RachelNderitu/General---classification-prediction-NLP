{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachelNderitu/RachelNderitu/blob/main/Transfer_Learning(Cats_and_Dogs)_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomContrast, RandomZoom"
      ],
      "metadata": {
        "id": "DUWORHZqGjSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract the dataset\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "metadata": {
        "id": "97OZUzNGGpeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train and validation directories\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "# Define batch size and image size\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "# Load train and validation datasets\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
        "                                                                 shuffle=True,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 image_size=IMG_SIZE)\n",
        "\n",
        "class_names = train_dataset.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6W7Kfb0GuSr",
        "outputId": "ca4f22ed-8b85-4353-b421-66e20aa14a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and augmentation\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Define data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "  RandomContrast(0.1),\n",
        "  RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "# Preprocess input images\n",
        "preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "# Load ResNet50 model\n",
        "base_model = ResNet50(input_shape=IMG_SIZE + (3,),\n",
        "                      include_top=False,\n",
        "                      weights='imagenet')"
      ],
      "metadata": {
        "id": "r-7b4FXZHBRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the model\n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
      ],
      "metadata": {
        "id": "sZsAJormHD2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "initial_epochs = 10\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)\n",
        "\n",
        "# Fine-tune the model\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 140  # Fine-tuning from this layer onwards\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate / 10),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "XBxyZUx3HRJ4",
        "outputId": "97ca9f6e-5045-415e-8f51-dd38d65cb054"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7c0a638ee27>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minitial_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(train_dataset,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     validation_data=validation_dataset)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model\n",
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(\"Fine-tuned model validation loss:\", loss)\n",
        "print(\"Fine-tuned model validation accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "predictions = model.predict(validation_dataset)\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "true_labels = np.concatenate([y for x, y in validation_dataset], axis=0)\n",
        "precision = precision_score(true_labels, binary_predictions)\n",
        "recall = recall_score(true_labels, binary_predictions)\n",
        "f1_score = 2 * ((precision * recall) / (precision + recall))\n",
        "\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1_score)"
      ],
      "metadata": {
        "id": "Jzkao4ElQ7T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display images and their predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in validation_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(f\"Prediction: {'Dog' if binary_predictions[i] == 1 else 'Cat'}, True Label: {class_names[labels[i]]}\")\n",
        "        plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2c6dzrRIRDsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}